## Leveraging Retry Logic in Spring AI

With the current code, an invalid answer exception is thrown if the Language Model (LM) provides an incorrect response. It would be beneficial to give the LM another chance to provide a valid answer. Spring AI offers support for retry operations to achieve this.

As a developer, you can use the `@Retryable` annotation on top of a REST API method to enable retries.

```java
@Retryable(value = InvalidAnswerException.class)
public String yourRestApiMethod() {
    // Your logic here
}
```

This annotation instructs the Spring AI framework to retry sending the prompt to the LM in case of an `InvalidAnswerException`.

*   By default, the framework retries three times.
*   If the LM still fails to provide a correct answer after three attempts, a runtime exception is thrown to the end user.

You can modify the default number of retries using the `maxAttempts` property.

```java
@Retryable(value = InvalidAnswerException.class, maxAttempts = 3)
public String yourRestApiMethod() {
    // Your logic here
}
```

üìù **Note:** The default value for `maxAttempts` is three.

‚ö†Ô∏è **Warning:** Avoid setting `maxAttempts` to high values (e.g., 5, 6, or 10) as it can cause the end user to wait for an extended period.

In addition to the controller class changes, you need to make the following changes:

1.  In the Spring Boot main class, add the `@EnableRetry` annotation to enable the retry functionality.

    ```java
    @SpringBootApplication
    @EnableRetry
    public class YourApplication {
        public static void main(String[] args) {
            SpringApplication.run(YourApplication.class, args);
        }
    }
    ```

    This enables the retry functionality provided by the Spring framework.

2.  Since the retry logic utilizes Spring's Aspect-Oriented Programming (AOP) concepts, ensure that you add the `spring-aspects` dependency to your `pom.xml`.

    ```xml
    <dependency>
        <groupId>org.springframework</groupId>
        <artifactId>spring-aspects</artifactId>
    </dependency>
    ```

    After adding the dependency, sync the Maven changes and rebuild the application.

### Handling Exceptions After Retries

Even after multiple retries, the LM might still return an invalid answer. To display a meaningful message to the end user instead of a runtime exception, you can leverage the retry library's recovery mechanism.

Create a `recover` method in your controller that returns a string. This method should accept the same exception type for which you are performing the retry operation.

```java
@Recover
public String recover(InvalidAnswerException e) {
    return "I'm sorry, I could not answer your question. Please try rephrasing it.";
}
```

Add the `@Recover` annotation on top of this method. The framework will retry the logic for the specified number of times. If the exception persists, it will execute the logic within the `recover` method.

When defining the `recover` method, adhere to these guidelines:

*   The return type of the `recover` method must match the return type of your retry method.
*   The `recover` method must accept the same exception type for which you are performing the retry operation.

### Spring AI Evaluators

üí° **Tip:** When using Spring AI evaluators, consider the following:

Spring AI evaluator provides two types of evaluators:

*   Relevancy evaluator: Checks the relevancy of the answer.
*   Correctness evaluator: Checks the correctness of the answer.

When using the relevancy evaluator, there's still a chance the end user might receive an invalid answer, even if it's related to the question. Therefore, it's highly recommended to use the fact-checking evaluator, which validates the correctness of the answer.

üìå **Example:** Fact Checking Evaluator

The Spring AI framework team recommends using specialized models like B-scope mini check, a grounded factuality checking model developed by Scope Labs and available in Olama, for efficient and accurate fact-checking. These models are designed to fact-check responses generated by other models, helping to detect and reduce hallucinations.

For more information, refer to the research paper and blog provided by Olama.

*   [White Paper on Efficient Fact Checking](link_to_whitepaper)
*   [Olama Blog on Reducing Hallucinations](link_to_olama_blog)

The B-scope mini check model can be set up using Olama in your own environment. This offers the advantage of avoiding extra charges from vendors like OpenAI.

All evaluation checks can be forwarded to this model, which performs a decent job.

We have already discussed how to set up an LM model using Olama and establish integration between a Spring AI application and Olama-based LM models.
